{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdGFUFTgPpTK",
        "colab_type": "text"
      },
      "source": [
        "Based on https://github.com/KevinLTT/video2bvh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxzdZdlRgkFW",
        "colab_type": "text"
      },
      "source": [
        "**HOW TO**\n",
        "*  Find out GPU model\n",
        "*  Install libs/deps\n",
        "*  Get openpose sources and build\n",
        "*  Download prebuild or build\n",
        "*  Try generate BVH\n",
        "\n",
        "\n",
        "**DO NOT USE LONG VIDEO**\n",
        "\n",
        "*otherwise it takes forever or bvh could be unusable*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98NAIOANx25T",
        "colab_type": "text"
      },
      "source": [
        "This Virtual Machine will be alive next **12hrs** or until \"Runtime->factory reset\"\n",
        "\n",
        "https://research.google.com/colaboratory/faq.html#idle-timeouts\n",
        "\n",
        "\n",
        "\n",
        "Find out GPU model, is usually one of:\n",
        "\n",
        "* \"Tesla T4\"\n",
        "* \"Tesla P4\"\n",
        "* \"Tesla P100-PCIE\"\n",
        "* \"Tesla K80\"\n",
        "\n",
        "If someting not works - try **Factory reset to obtain another GPU**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uM1ToeX6Iol3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Get system info\n",
        "! lsb_release -a\n",
        "#Get GPU info\n",
        "! nvcc --version\n",
        "! nvidia-smi\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtjHA7UUQ_gh",
        "colab_type": "text"
      },
      "source": [
        "Download all sources:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mOyX-eSCvZy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git init\n",
        "!echo \".*\" > .gitignore\n",
        "!git remote add origin https://github.com/andriitishchenko/video2bvh.git\n",
        "!git fetch\n",
        "!git checkout master\n",
        "!git submodule update --init --recursive\n",
        "!cd openpose/models/pose/body_25/ && curl -L -C - http://posefs1.perception.cs.cmu.edu/OpenPose/models/pose/body_25/pose_iter_584000.caffemodel -O\n",
        "\n",
        "# # download ALL models\n",
        "# !cd openpose/models/ && ./getModels.sh\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMcj3xnddgTM",
        "colab_type": "text"
      },
      "source": [
        "* Install Libs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPqYOS1M1fng",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Install latest cmake, default is cmake 3.13\n",
        "! sudo apt-get purge cmake\n",
        "! curl -L https://github.com/Kitware/CMake/releases/download/v3.18.0-rc3/cmake-3.18.0-rc3-Linux-x86_64.sh -O \n",
        "! chmod +x cmake-3.18.0-rc3-Linux-x86_64.sh\n",
        "! ./cmake-3.18.0-rc3-Linux-x86_64.sh --skip-license --prefix=/usr/local\n",
        "! cmake --version\n",
        "! rm cmake-3.18.0-rc3-Linux-x86_64.sh\n",
        "\n",
        "! sudo apt-get --assume-yes update\n",
        "! sudo apt-get --assume-yes install libatlas-base-dev libprotobuf-dev libleveldb-dev libsnappy-dev libhdf5-serial-dev protobuf-compiler libopencv-dev\n",
        "! sudo apt-get --assume-yes install build-essential libatlas-base-dev libprotobuf-dev libleveldb-dev libsnappy-dev libhdf5-serial-dev protobuf-compiler\n",
        "! sudo apt-get --assume-yes install libgflags-dev libgoogle-glog-dev liblmdb-dev\n",
        "\n",
        "# OpenCL Generic\n",
        "! sudo apt-get --assume-yes install opencl-headers ocl-icd-opencl-dev\n",
        "! sudo apt-get --assume-yes install libviennacl-dev\n",
        "\n",
        "# OpenCV\n",
        "! sudo apt-get --assume-yes install libopencv-dev\n",
        "\n",
        "# Tools\n",
        "!sudo apt install imagemagick\n",
        "\n",
        "# ======================\n",
        "! pip3 install --upgrade pip\n",
        "! pip3 uninstall albumentations -y\n",
        "! pip3 install --upgrade opencv-python albumentations\n",
        "! pip install progressbar2\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/openpose/build/python/openpose')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWe3e16qDpt4",
        "colab_type": "text"
      },
      "source": [
        "**Create link to your Google drive for models:**\n",
        "\n",
        "https://drive.google.com/drive/folders/1M2s32xQkrDhDLz-VqzvocMuoaSGR1MfX\n",
        "\n",
        "*  Mount and copy models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xo7hnZ11d7az",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "# mount Google Drive\n",
        "# When you mount it, you will be asked for permission, so allow it, \n",
        "# copy the key, paste it in the input field on the Colab side, and press Enter.\n",
        "drive.mount('/gdrive')\n",
        "# copy pretrained linked models \n",
        "!cp -r \"/gdrive/My Drive/models/\" ./models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoBJvFBX6pra",
        "colab_type": "text"
      },
      "source": [
        "Python 3 + cuda **builded**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVwqasNdZGB0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### check if GPU one of \"Tesla T4\",\"Tesla P4\",\"Tesla P100-PCIE\",\"Tesla K80\"\n",
        "### if GPU not listed - build from sources\n",
        "### if openpose not works - build from sources\n",
        "! rm -rf openpose/build/\n",
        "\n",
        "### Tesla P100-PCIE\n",
        "# ! curl -L -C - https://github.com/andriitishchenko/openpose_demo/raw/master/ubuntu/build_cuda_py3_Tesla_P100-PCIE.zip -o build.zip\n",
        "\n",
        "### Tesla P4\n",
        "# ! curl -L -C - https://github.com/andriitishchenko/openpose_demo/raw/master/ubuntu/build_cuda_py3_Tesla_P4.zip -o build.zip\n",
        "\n",
        "### Tesla T4\n",
        "# ! curl -L -C - https://github.com/andriitishchenko/openpose_demo/raw/master/ubuntu/build_cuda_py3_Tesla_T4.zip -o build.zip\n",
        "\n",
        "### Tesla K80\n",
        "# ! curl -L -C - https://github.com/andriitishchenko/openpose_demo/raw/master/ubuntu/build_cuda_py3_Tesla_K80.zip -o build.zip\n",
        "! unzip build.zip -d openpose/\n",
        "!echo \"DONE ...\"\n",
        "\n",
        "###  OR BUILD from sources, it takes ~20min, python3 using\n",
        "# build_dir=\"build\"\n",
        "# ! rm -rf \"openpose/$build_dir\"\n",
        "# ! mkdir \"openpose/$build_dir\"\n",
        "# ! cd \"openpose/$build_dir\" && cmake .. -DBUILD_PYTHON=On\n",
        "# ! cd \"openpose/$build_dir\" && make -j`nproc`\n",
        "# !echo \"DONE ...\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42rMDcQVX0Wj",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZx_haE57dLn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pose_estimator_2d import openpose_estimator\n",
        "from pose_estimator_3d import estimator_3d\n",
        "from utils import smooth, vis, camera\n",
        "from bvh_skeleton import openpose_skeleton, h36m_skeleton, cmu_skeleton\n",
        "\n",
        "import sys\n",
        "import cv2\n",
        "import importlib\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from IPython.display import HTML\n",
        "import time\n",
        "import progressbar\n",
        "\n",
        "# set model_folder to /path/to/openpose/models\n",
        "e2d = openpose_estimator.OpenPoseEstimator(model_folder='openpose/models/') \n",
        "\n",
        "# video file to process:\n",
        "# \"miscs/cxk.mp4\" - predefined \n",
        "video_file = Path(\"/gdrive/My Drive/bvh/1.mp4\") \n",
        "output_dir = Path(f'miscs/{video_file.stem}_cache')\n",
        "\n",
        "!rm -rf $output_dir\n",
        "\n",
        "if not output_dir.exists():\n",
        "    os.makedirs(output_dir)\n",
        "    \n",
        "cap = cv2.VideoCapture(str(video_file))\n",
        "totalFrames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "bar = progressbar.ProgressBar(max_value=totalFrames)\n",
        "keypoints_list = []\n",
        "img_width, img_height = None, None\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    nextFrameNo = cap.get(cv2.CAP_PROP_POS_FRAMES)\n",
        "    bar.update(nextFrameNo)\n",
        "\n",
        "    img_height = frame.shape[0]\n",
        "    img_width = frame.shape[1]\n",
        "    \n",
        "    # returned shape will be (num_of_human, 25, 3)\n",
        "    # last dimension includes (x, y, confidence)\n",
        "    keypoints = e2d.estimate(img_list=[frame])[0]\n",
        "    if isinstance(keypoints, np.ndarray) and len(keypoints.shape) == 3:\n",
        "        keypoints_list.append(keypoints[0])\n",
        "\n",
        "cap.release()\n",
        "print(\"\")\n",
        "\n",
        "# filter out failed result\n",
        "keypoints_list = smooth.filter_missing_value(\n",
        "    keypoints_list=keypoints_list,\n",
        "    method='ignore' # interpolation method will be implemented later\n",
        ")\n",
        "\n",
        "# smooth process will be implemented later\n",
        "\n",
        "# save 2d pose result\n",
        "pose2d = np.stack(keypoints_list)[:, :, :2]\n",
        "pose2d_file = Path(output_dir / '2d_pose.npy')\n",
        "np.save(pose2d_file, pose2d)\n",
        "print(\"Saved to:\")\n",
        "print(pose2d_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hIM0OeaYucS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Visualize 2D pose, not requaried for bvh\n",
        "## this will fail if video has no people frames\n",
        "\n",
        "### uncoment if nedded\n",
        "\n",
        "# cap = cv2.VideoCapture(str(video_file))\n",
        "# bar = progressbar.ProgressBar(max_value=len(keypoints_list))\n",
        "# vis_result_dir = output_dir / '2d_pose_vis' # path to save the visualized images\n",
        "# if not vis_result_dir.exists():\n",
        "#     os.makedirs(vis_result_dir)\n",
        "    \n",
        "# op_skel = openpose_skeleton.OpenPoseSkeleton()\n",
        "\n",
        "# for i, keypoints in enumerate(keypoints_list):\n",
        "#     ret, frame = cap.read()\n",
        "#     if not ret:\n",
        "#         break\n",
        "#     ### keypoint whose detect confidence under kp_thresh will not be visualized\n",
        "#     vis.vis_2d_keypoints(\n",
        "#         keypoints=keypoints,\n",
        "#         img=frame,\n",
        "#         skeleton=op_skel,\n",
        "#         kp_thresh=0.4,\n",
        "#         output_file=vis_result_dir / f'{i:04d}.png'\n",
        "#     )\n",
        "#     bar.update(i)\n",
        "\n",
        "# cap.release()\n",
        "# print(\"\")\n",
        "# print(\"Done...\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsuCd5Enm4O2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize 3D pose estimator\n",
        "print(\"Initialize 3D pose estimator ...\")\n",
        "importlib.reload(estimator_3d)\n",
        "e3d = estimator_3d.Estimator3D(\n",
        "    config_file='models/openpose_video_pose_243f/video_pose.yaml',\n",
        "    checkpoint_file='models/openpose_video_pose_243f/best_58.58.pth'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsQaN3nBm54_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Estimate 3D pose from 2D pose\n",
        "print(\"Estimate 3D pose from 2D pose ...\")\n",
        "# import torch\n",
        "# torch.cuda.empty_cache()\n",
        "pose2d = np.load(pose2d_file)\n",
        "pose3d = e3d.estimate(pose2d, image_width=img_width, image_height=img_height)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlgVDFW5m7wM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert coordinates\n",
        "print(\"convert coordinates ...\")\n",
        "subject = 'S1'\n",
        "cam_id = '55011271'\n",
        "cam_params = camera.load_camera_params('cameras.h5')[subject][cam_id]\n",
        "R = cam_params['R']\n",
        "T = 0\n",
        "azimuth = cam_params['azimuth']\n",
        "\n",
        "pose3d_world = camera.camera2world(pose=pose3d, R=R, T=T)\n",
        "pose3d_world[:, :, 2] -= np.min(pose3d_world[:, :, 2]) # rebase the height\n",
        "\n",
        "pose3d_file = output_dir / '3d_pose.npy'\n",
        "np.save(pose3d_file, pose3d_world)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8Y2zZaWT0d_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Visualize 3D pose, not requaried for bvh\n",
        "### uncoment if nedded\n",
        "\n",
        "# h36m_skel = h36m_skeleton.H36mSkeleton()\n",
        "# gif_file = f'{output_dir}/3d_pose_300_{video_file.stem}.gif' # output format can be .gif or .mp4 \n",
        "# print(gif_file)\n",
        "# ani = vis.vis_3d_keypoints_sequence(\n",
        "#     keypoints_sequence=pose3d_world[0:300],\n",
        "#     skeleton=h36m_skel,\n",
        "#     azimuth=azimuth,\n",
        "#     fps=60,\n",
        "#     output_file=gif_file\n",
        "# )\n",
        "# HTML(ani.to_jshtml())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Y5BHRoLhJ6Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create bvh\n",
        "print(\"Create bvh ...\")\n",
        "bvh_file = output_dir / f'{video_file.stem}.bvh'\n",
        "cmu_skel = cmu_skeleton.CMUSkeleton()\n",
        "channels, header = cmu_skel.poses2bvh(pose3d_world, output_file=bvh_file)\n",
        "\n",
        "output = f'miscs/h36m_{video_file.stem}.bvh'\n",
        "h36m_skel = h36m_skeleton.H36mSkeleton()\n",
        "_ = h36m_skel.poses2bvh(pose3d_world, output_file=output)\n",
        "\n",
        "#perform dowmload\n",
        "from google.colab import files\n",
        "files.download(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "### Processing mp4 files in Google Drive folder\n",
        "#           (start time)                   (duration time) \n",
        "# ffmpeg -ss 00:01:20 -i input_video.mp4 -t 00:00:10 -vcodec copy -acodec copy -y out_part_1.mp4\n",
        "#\n",
        "###\n",
        "\n",
        "from pose_estimator_2d import openpose_estimator\n",
        "from pose_estimator_3d import estimator_3d\n",
        "from utils import smooth, vis, camera\n",
        "from bvh_skeleton import openpose_skeleton, h36m_skeleton, cmu_skeleton\n",
        "\n",
        "import sys\n",
        "import cv2\n",
        "import importlib\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from IPython.display import HTML\n",
        "import time\n",
        "import progressbar\n",
        "import os\n",
        "\n",
        "e2d = openpose_estimator.OpenPoseEstimator(model_folder='openpose/models/') \n",
        "\n",
        "directory = r'/gdrive/My Drive/bvh/1080/'\n",
        "for filename in os.listdir(directory):\n",
        "    if filename.endswith(\".mp4\"):\n",
        "        video_file = Path(os.path.join(directory, filename))\n",
        "        print(video_file)\n",
        "\n",
        "        # video_file = Path(\"/gdrive/My Drive/bvh/1080/p9.mp4\") \n",
        "        output_dir = Path(f'miscs/{video_file.stem}_cache')\n",
        "\n",
        "        !rm -rf $output_dir\n",
        "\n",
        "        if not output_dir.exists():\n",
        "            os.makedirs(output_dir)\n",
        "            \n",
        "        cap = cv2.VideoCapture(str(video_file))\n",
        "        totalFrames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "        bar = progressbar.ProgressBar(max_value=totalFrames)\n",
        "        keypoints_list = []\n",
        "        img_width, img_height = None, None\n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            nextFrameNo = cap.get(cv2.CAP_PROP_POS_FRAMES)\n",
        "            bar.update(nextFrameNo)\n",
        "\n",
        "            img_height = frame.shape[0]\n",
        "            img_width = frame.shape[1]\n",
        "            \n",
        "            # returned shape will be (num_of_human, 25, 3)\n",
        "            # last dimension includes (x, y, confidence)\n",
        "            keypoints = e2d.estimate(img_list=[frame])[0]\n",
        "            if isinstance(keypoints, np.ndarray) and len(keypoints.shape) == 3:\n",
        "                keypoints_list.append(keypoints[0])\n",
        "\n",
        "        cap.release()\n",
        "        print(\"\")\n",
        "\n",
        "        # filter out failed result\n",
        "        keypoints_list = smooth.filter_missing_value(\n",
        "            keypoints_list=keypoints_list,\n",
        "            method='ignore' # interpolation method will be implemented later\n",
        "        )\n",
        "\n",
        "        # smooth process will be implemented later\n",
        "\n",
        "        # save 2d pose result\n",
        "        pose2d = np.stack(keypoints_list)[:, :, :2]\n",
        "        pose2d_file = Path(output_dir / '2d_pose.npy')\n",
        "        np.save(pose2d_file, pose2d)\n",
        "        print(\"Saved to:\")\n",
        "        print(pose2d_file)\n",
        "\n",
        "        # =====# Initialize 3D pose estimator\n",
        "        print(\"Initialize 3D pose estimator ...\")\n",
        "        importlib.reload(estimator_3d)\n",
        "        e3d = estimator_3d.Estimator3D(\n",
        "            config_file='models/openpose_video_pose_243f/video_pose.yaml',\n",
        "            checkpoint_file='models/openpose_video_pose_243f/best_58.58.pth'\n",
        "        )\n",
        "\n",
        "        # =====\n",
        "        # Estimate 3D pose from 2D pose\n",
        "        print(\"Estimate 3D pose from 2D pose ...\")\n",
        "        # import torch\n",
        "        # torch.cuda.empty_cache()\n",
        "        pose2d = np.load(pose2d_file)\n",
        "        pose3d = e3d.estimate(pose2d, image_width=img_width, image_height=img_height)\n",
        "\n",
        "        # ======\n",
        "        # convert coordinates\n",
        "        print(\"convert coordinates ...\")\n",
        "        subject = 'S1'\n",
        "        cam_id = '55011271'\n",
        "        cam_params = camera.load_camera_params('cameras.h5')[subject][cam_id]\n",
        "        R = cam_params['R']\n",
        "        T = 0\n",
        "        azimuth = cam_params['azimuth']\n",
        "\n",
        "        pose3d_world = camera.camera2world(pose=pose3d, R=R, T=T)\n",
        "        pose3d_world[:, :, 2] -= np.min(pose3d_world[:, :, 2]) # rebase the height\n",
        "\n",
        "        pose3d_file = output_dir / '3d_pose.npy'\n",
        "        np.save(pose3d_file, pose3d_world)\n",
        "\n",
        "        # =====\n",
        "        # Create bvh\n",
        "        print(\"Create bvh ...\")\n",
        "        bvh_file = output_dir / f'{video_file.stem}.bvh'\n",
        "        cmu_skel = cmu_skeleton.CMUSkeleton()\n",
        "        channels, header = cmu_skel.poses2bvh(pose3d_world, output_file=bvh_file)\n",
        "\n",
        "        output = f'miscs/h36m_{video_file.stem}.bvh'\n",
        "        h36m_skel = h36m_skeleton.H36mSkeleton()\n",
        "        _ = h36m_skel.poses2bvh(pose3d_world, output_file=output)\n",
        "\n",
        "        dist_full_path = f'\"{directory}\"'\n",
        "        !cp {output} {dist_full_path}\n",
        "        print(f\"COPIED: {dist_full_path}\")\n",
        "        #perform dowmload\n",
        "        # from google.colab import files\n",
        "        # files.download(output)\n",
        "    else:\n",
        "        continue\n",
        "print(\"DONE...\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "BVH.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}